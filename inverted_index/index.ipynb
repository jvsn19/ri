{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequencyDocument(json_dict, file_index):\n",
    "    w = []\n",
    "    for words in json_dict.values():\n",
    "        if words in ['', '--', ' ', '.', ' -']:\n",
    "            continue\n",
    "        w.append(words)\n",
    "\n",
    "    matrix = []\n",
    "    try:\n",
    "        matrix = vectorizer.fit_transform(w).toarray()\n",
    "    except:\n",
    "        return\n",
    "    matrix = matrix.sum(axis = 0)\n",
    "\n",
    "    for word, index in vectorizer.vocabulary_.items():\n",
    "        freqDoc = (int(matrix[index]), int(file_index))\n",
    "        if not inv_index_frequency.get(word, False):\n",
    "            inv_index_frequency[word] = set()\n",
    "        inv_index_frequency[word].add(freqDoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twoTermsDocument(json_dict, file_index):\n",
    "    for key, words in json_dict.items():\n",
    "        if words in ['', '--', ' ', '.', ' -']:\n",
    "            continue\n",
    "        words = words.strip().split(' ')\n",
    "        words = words + [' '.join(t) for t in ngrams(words, 2)]\n",
    "        diff_words = set()\n",
    "        for word in words:\n",
    "            cont = 0\n",
    "            if word in ['', '--', ' ', '.', '-', ',']:\n",
    "                continue\n",
    "            for word2 in words:\n",
    "                if(word == word2):\n",
    "                    cont += 1\n",
    "            if not word in diff_words:\n",
    "                freqDoc = (cont, word)\n",
    "                diff_words.add(freqDoc)\n",
    "            else:\n",
    "                continue\n",
    "        for freq, word in diff_words:        \n",
    "            newKey = word + '.' + key\n",
    "            freqDoc = (int(freq), int(file_index))\n",
    "            if not inv_index_twoTermsDocs.get(newKey, False):\n",
    "                inv_index_twoTermsDocs[newKey] = set()\n",
    "            inv_index_twoTermsDocs[newKey].add(freqDoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_index_frequency = {}\n",
    "inv_index_twoTermsDocs = {}\n",
    "path_db = os.path.abspath('./db')\n",
    "for file_name in os.listdir(path_db):\n",
    "    file_path = path_db + '/' + file_name\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        file_text = file.read()\n",
    "        file_text = re.sub(r'\\\\xc2|\\\\xae|\\\\xe2|\\\\x80|\\\\x99|\\\\x84|\\\\xa2|\\\\x93|\\\\xa0|\\\\', '', file_text)\n",
    "        json_dict = json.loads(file_text[:-1])\n",
    "    frequencyDocument(json_dict, file_name)\n",
    "    twoTermsDocument(json_dict, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in inv_index_frequency.keys():\n",
    "    inv_index_frequency[key] = sorted(inv_index_frequency[key], key = lambda val: val[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in inv_index_twoTermsDocs.keys():\n",
    "    inv_index_twoTermsDocs[key] = sorted(inv_index_twoTermsDocs[key], key = lambda val: val[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveJSON(dict_file, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as fp:\n",
    "        json_text = json.dumps(dict_file, ensure_ascii=False).encode('utf-8')\n",
    "        fp.write(str(json_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveJSON(inv_index_frequency, 'frequency.json')\n",
    "saveJSON(inv_index_twoTermsDocs, 'twoTerms.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of file Frequency: 2257.34 kB\n",
      "Size of file TwoTerms: 2898.91 kB\n"
     ]
    }
   ],
   "source": [
    "print('Size of file Frequency: %.2f kB'%(os.path.getsize('frequency.json')/1024.0))\n",
    "print('Size of file TwoTerms: %.2f kB'%(os.path.getsize('twoTerms.json')/1024.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in inv_index_twoTermsDocs:\n",
    "    for i in range(len(inv_index_twoTermsDocs[key])-1, 0, -1):\n",
    "        freqDoc = (inv_index_twoTermsDocs[key][i][0], inv_index_twoTermsDocs[key][i][1]-inv_index_twoTermsDocs[key][i-1][1])\n",
    "        inv_index_twoTermsDocs[key][i] = freqDoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveJSON(inv_index_twoTermsDocs, 'twoTermsCompressed.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in inv_index_frequency:\n",
    "    for i in range(len(inv_index_frequency[key])-1, 0, -1):\n",
    "        freqDoc = (inv_index_frequency[key][i][0], inv_index_frequency[key][i][1]-inv_index_frequency[key][i-1][1])\n",
    "        inv_index_frequency[key][i] = freqDoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveJSON(inv_index_frequency, 'frequencyCompressed.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of file Frequency: 1975.14 kB\n",
      "Size of file TwoTerms: 2594.38 kB\n"
     ]
    }
   ],
   "source": [
    "print('Size of file Frequency: %.2f kB'%(os.path.getsize('frequencyCompressed.json')/1024.0))\n",
    "print('Size of file TwoTerms: %.2f kB'%(os.path.getsize('twoTermsCompressed.json')/1024.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 771), (1, 1), (1, 1), (2, 1)]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_index_frequency['dark souls']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
